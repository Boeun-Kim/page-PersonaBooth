<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="PersonaBooth: Personalized Text-to-Motion Generation">
  <meta name="keywords" content="PersonaBooth, Motion Style Transfer, Human Motion, Motion Generation, Diffusion, Text-to-Motion">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>PersonaBooth: Personalized Text-to-Motion Generation</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
  <script type="text/x-mathjax-config">

    MathJax.Hub.Config({
    
      tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}
    
    });
    
    </script>
    
    <script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-MML-AM_CHTML' async></script>
</head>
<body>

<nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
  <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
      <a class="navbar-item" href="https://github.com/Boeun-Kim">
      <span class="icon">
          <i class="fas fa-home"></i>
      </span>
      </a>

      <div class="navbar-item has-dropdown is-hoverable">
        <a class="navbar-link">
          More Research
        </a>
        <div class="navbar-dropdown">
          <a class="navbar-item" href="https://Boeun-Kim.github.io/page-GL-Transformer">
            GL-Transformer
          </a>
          <a class="navbar-item" href="https://Boeun-Kim.github.io/page-MoST">
            MoST
          </a>
        </div>
      </div>
    </div>

  </div>
</nav>


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">PersonaBooth: Personalized Text-to-Motion Generation</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://drive.google.com/file/d/1-tSRPaRkok53CVLtK4w1Ix35pvJ9iZh3/view?usp=drive_link">Boeun Kim</a><sup>1,2,3</sup>,</span>
            <span class="author-block">
              <a>Hea In Jeong</a><sup>2</sup>,</span>
            <span class="author-block">
              <a>JungHoon Sung</a><sup>3</sup>,</span>
            <span class="author-block">
              <a>Yihua Cheng</a><sup>1</sup>,</span>
            <span class="author-block">
              <a>Jeongmin Lee</a><sup>2</sup>,</span>
            <span class="author-block">
              <a>Ju Yong Chang</a><sup>4</sup>,</span>
            <span class="author-block">
              <a>Sang-Il Choi</a><sup>3</sup>,</span>
            <span class="author-block">
              <a>Younggeun Choi</a><sup>3</sup>,</span>
            <span class="author-block">
              <a>Saim Shin</a><sup>2</sup>,</span>
            <span class="author-block">
              <a>Jungho Kim</a><sup>2</sup>,</span>
            <span class="author-block">
              <a>Hyung Jin Chang</a><sup>1</sup>,</span>
          </div>
          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>University of Birmingham, </span>
            <span class="author-block"><sup>2</sup>Korea Electronics Technology Institute, </span>
            <span class="author-block"><sup>3</sup>Dankook University, </span>
            <span class="author-block"><sup>4</sup>KwangWoon University</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://arxiv.org/pdf/2503.07390"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <!-- Video Link. -->
              <span class="link-block">
                <a href=""
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
              </span>
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/Boeun-Kim/PersonaBooth"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
              <!-- Data Link. -->
              <span class="link-block">
                <a href="https://github.com/AIRC-KETI-VISION/PerMo-dataset"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fa fa-database"></i>
                  </span>
                  <span>Data</span>
                  </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <video id="teaser" autoplay muted loop playsinline height="100%">
            <source src="./static/videos/test.mp4"
                    type="video/mp4">
          </video>
          <h2 class="subtitle has-text-centered">
            Motion Personalization generates text-driven, personalized motions based on persona embedded in atomic input motions. We define a persona as the unique style expression of an individual.
          </h2>
        </div>
      </div>
    </div>
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          This paper introduces Motion Personalization, a new task that generates personalized motions aligned with text descriptions using several basic motions containing Persona.
          To support this novel task, we introduce a new large-scale motion dataset called <b>PerMo (PersonaMotion)</b>, which captures the unique personas of multiple actors. 
          We also propose a multi-modal finetuning method of a pretrained motion diffusion model called <b>PersonaBooth</b>. 
          PersonaBooth addresses two main challenges: 
          i) A significant distribution gap between the persona-focused PerMo dataset and the pretraining datasets, which lack persona-specific data, and
          ii) the difficulty of capturing a consistent persona from the motions vary in content (action type). 
          To tackle the dataset distribution gap, we introduce a persona token to accept new persona features and perform multi-modal adaptation for both text and visuals during finetuning. 
          To capture a consistent persona, we incorporate a contrastive learning technique to enhance intra-cohesion among samples with the same persona. 
          Furthermore, we introduce a contextaware fusion mechanism to maximize the integration of persona cues from multiple input motions. 
          PersonaBooth outperforms state-of-the-art motion style transfer methods, establishing a new benchmark for motion personalization.
        </div>
      </div>
    </div>
    <!--/ Abstract. -->

    <!-- Paper video.
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Video</h2>
        <div class="publication-video">
          <iframe src="https://www.youtube.com/embed/cLWswPCF-8I"
                  frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
        </div>
      </div>
    </div>
    / Paper video. -->

  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <!-- Framework. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Framework</h2>
        <img src="./static/images/framework.png" />
          <div class="content has-text-justified">
            The overall framework of PersonaBooth. PersonaBooth has two adaptation paths—visual and text—for finetuning the Motion Diffusion model ($\mathcal{D}$). 
            The Persona Extractor extracts both a visual persona feature ($V^∗$) and a persona token ($P^∗$) from the input motions.
            $V^∗$ is input into the adaptive layer of $\mathcal{D}$, while $P^∗$ is processed together with the input prompt through a Personalized Text Encoder,
            generating a personalized text feature, which is then input to $\mathcal{D}$. 
            The entire model is trained with a classifier-free approach, incorporating a Persona Cohesion Loss.
            During inference, Context-Aware Fusion is applied for multiple input cases.
        </div>

      </div>
    </div>
    <!--/ Framework. -->
  </div>
</section>


<section class="dataset">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Dataset</h2>
          <video id="dataset" autoplay muted loop playsinline height="100%">
            <source src="./static/videos/dataset.mp4"
                    type="video/mp4">
          </video>
            <div class="content has-text-justified">
              We collected a large-scale PerMo dataset, capturing personas from multiple actors. 
              To ensure variety, we hired five professional motion capture actors of diverse genders and body types. 
              Each actor is assigned to perform 34 styles, categorized into <i>Age, Character, Condition, Emotion, Traits</i>, and <i>Surroundings</i>, resulting in a total of 170 personas. 
              Each actor performed 10 distinct contents for every style, carefully selected to engage different body parts.
              Notably, PerMo is the first dataset to collect data from multiple actors. 
              Our dataset also offers the highest number of total clips and content categories among trainable datasets and is the only one that includes mesh, marker data, and descriptions.
        </div>
      </div>
    </div>
  </div>
</section>
  
<section class="hero is-light is-small">
  <div class="hero-body">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Results of PersonaBooth</h2>
        <div class="content has-text-justified">
          <h3 class="title is-4 has-text-left">Distinct persona expressions across actors</h3>
          <video id="distinct" autoplay muted loop playsinline height="100%">
            <source src="./static/videos/distinct.mp4"
                    type="video/mp4">
          </video>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero is-light is-small">
  <div class="hero-body">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <div class="content has-text-justified">
          <h3 class="title is-4 has-text-left">Ablation study</h3>
          <video id="ablation" autoplay muted loop playsinline height="100%">
            <source src="./static/videos/ablation.mp4"
                    type="video/mp4">
          </video>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero is-light is-small">
  <div class="hero-body">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <div class="content has-text-justified">
          <h3 class="title is-4 has-text-left">Comparisons - PerMo Dataset</h3>
          <video id="ablation" autoplay muted loop playsinline height="100%">
            <source src="./static/videos/permo.mp4"
                    type="video/mp4">
          </video>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero is-light is-small">
  <div class="hero-body">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <div class="content has-text-justified">
          <h3 class="title is-4 has-text-left">Comparisons - 100Style Dataset</h3>
          <video id="ablation" autoplay muted loop playsinline height="100%">
            <source src="./static/videos/100style.mp4"
                    type="video/mp4">
          </video>
        </div>
      </div>
    </div>
  </div>
</section>


<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@article{kim2025personabooth,
      title={PersonaBooth: Personalized Text-to-Motion Generation},
      author={Kim, Boeun and Jeong, Hea In and Sung, JungHoon and Cheng, Yihua and Lee, Jeongmin and Chang, Ju Yong and Choi, Sang-Il and Choi, Younggeun and Shin, Saim and Kim, Jungho and Chang, Hyung Jin},
      journal={arXiv preprint arXiv:2503.07390},
      year={2025}
}</code></pre>
  </div>
</section>


<footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
            This page was built using the <a
              href="https://github.com/eliahuhorwitz/Academic-project-page-template">template</a>.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
